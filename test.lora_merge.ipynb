{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b2d0a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\envs\\FL\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "from peft import get_peft_model, LoraConfig, TaskType, PeftModel\n",
    "import peft\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from MLP_function import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "725a356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seeds(45)\n",
    "# Data 1\n",
    "X_1 = torch.rand((500, 1, 28, 28, 28))\n",
    "# set_all_seeds(45)\n",
    "y_1 = (X_1.sum(dim=[1,2,3,4]) > 11000).long()  # Binary classification based on voxel sum\n",
    "\n",
    "# Data 2\n",
    "X_2 = torch.rand((500, 1, 28, 28, 28))\n",
    "# set_all_seeds(45)\n",
    "y_2 = (X_2.sum(dim=[1,2,3,4]) > 11000).long()  # Binary classification based on voxel sum\n",
    "\n",
    "# Data 3\n",
    "X_3 = torch.rand((500, 1, 28, 28, 28))\n",
    "# set_all_seeds(45)\n",
    "y_3 = (X_3.sum(dim=[1,2,3,4]) > 11000).long()  # Binary classification based on voxel sum\n",
    "\n",
    "n_train = 400\n",
    "batch_size = 32\n",
    "train_dataloader_1 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_1[:n_train], y_1[:n_train]),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "eval_dataloader_1 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_1[n_train:], y_1[n_train:]),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "train_dataloader_2 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_2[:n_train], y_2[:n_train]),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "eval_dataloader_2 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_2[n_train:], y_2[n_train:]),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "train_dataloader_3 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_3[:n_train], y_3[:n_train]),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "eval_dataloader_3 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_3[n_train:], y_3[n_train:]),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "lr = 0.002\n",
    "max_epochs = 20\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config = peft.LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"conv.0\", \"conv.3\", 'fc.0'],\n",
    "    # modules_to_save=[\"fc\"] ,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17c8b20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_model details:\n",
      "All params: mean= -0.000005, std=0.006723\n"
     ]
    }
   ],
   "source": [
    "# Base model\n",
    "original_model = CNN3D().to(device)\n",
    "original_model_copy = copy.deepcopy(original_model)\n",
    "all_params = torch.cat([param.data.view(-1) for param in original_model.parameters()])\n",
    "print('original_model details:')\n",
    "print(f\"All params: mean= {all_params.mean().item():.6f}, std={all_params.std().item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12433cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 get train loss: 0.7069319486618042 val loss: 0.5935408473014832\n",
      "Batch 1 get train loss: 0.6280664801597595 val loss: 0.5944093465805054\n",
      "Batch 2 get train loss: 0.6432785987854004 val loss: 0.6026040315628052\n",
      "Batch 3 get train loss: 0.6130321621894836 val loss: 0.5715664625167847\n",
      "Batch 4 get train loss: 0.6160570979118347 val loss: 0.5756078958511353\n",
      "Batch 5 get train loss: 0.6223089098930359 val loss: 0.5971855521202087\n",
      "Batch 6 get train loss: 0.621879518032074 val loss: 0.571010410785675\n",
      "Batch 7 get train loss: 0.623405933380127 val loss: 0.572990894317627\n",
      "Batch 8 get train loss: 0.6278942823410034 val loss: 0.570976972579956\n",
      "Batch 9 get train loss: 0.6140992641448975 val loss: 0.5857475399971008\n",
      "Batch 10 get train loss: 0.6092574000358582 val loss: 0.5711942315101624\n",
      "Batch 11 get train loss: 0.6117033362388611 val loss: 0.5811612606048584\n",
      "Batch 12 get train loss: 0.608684241771698 val loss: 0.5724223852157593\n",
      "Batch 13 get train loss: 0.6101047396659851 val loss: 0.5734221935272217\n",
      "Batch 14 get train loss: 0.6107649803161621 val loss: 0.5775948762893677\n",
      "Batch 15 get train loss: 0.6087150573730469 val loss: 0.5890299081802368\n",
      "Batch 16 get train loss: 0.6074486374855042 val loss: 0.5705541968345642\n",
      "Batch 17 get train loss: 0.6083042025566101 val loss: 0.5715371370315552\n",
      "Batch 18 get train loss: 0.6016075015068054 val loss: 0.5910356044769287\n",
      "Batch 19 get train loss: 0.5980290174484253 val loss: 0.576300323009491\n"
     ]
    }
   ],
   "source": [
    "### train base model with data 1\n",
    "optimizer = optim.Adam(original_model.parameters(), lr=0.001)\n",
    "criterion = nn.NLLLoss()\n",
    "train(original_model, optimizer, criterion, train_dataloader_1, eval_dataloader_1, device, epochs=max_epochs)\n",
    "# Save model checkpoints\n",
    "model_path = 'model_checkpoints/3DCNN_base'\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "torch.save(original_model.state_dict(), os.path.join(model_path, f\"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bdfc037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_model after train details:\n",
      "All params: mean= -0.001732, std=0.007998\n",
      "original_model_copy details:\n",
      "All params: mean= -0.000005, std=0.006723\n"
     ]
    }
   ],
   "source": [
    "original_model_all_params = torch.cat([param.data.view(-1) for param in original_model.parameters()])\n",
    "print('original_model after train details:')\n",
    "print(f\"All params: mean= {original_model_all_params.mean().item():.6f}, std={original_model_all_params.std().item():.6f}\")\n",
    "\n",
    "original_model_copy_all_params = torch.cat([param.data.view(-1) for param in original_model_copy.parameters()])\n",
    "print('original_model_copy details:')\n",
    "print(f\"All params: mean= {original_model_copy_all_params.mean().item():.6f}, std={original_model_copy_all_params.std().item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "678952c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model details:\n",
      "All params: mean= -0.001732, std=0.007998\n",
      "peft_model details:\n",
      "All params: mean= -0.001603, std=0.008132\n",
      "Batch 0 get train loss: 0.6083725690841675 val loss: 0.573870837688446\n",
      "Batch 1 get train loss: 0.5985857844352722 val loss: 0.5798882246017456\n",
      "Batch 2 get train loss: 0.5933542847633362 val loss: 0.5784934163093567\n",
      "Batch 3 get train loss: 0.5917235612869263 val loss: 0.5729011297225952\n",
      "Batch 4 get train loss: 0.5912915468215942 val loss: 0.5783311128616333\n",
      "Batch 5 get train loss: 0.5881150364875793 val loss: 0.5742651224136353\n",
      "Batch 6 get train loss: 0.5919513702392578 val loss: 0.573917031288147\n",
      "Batch 7 get train loss: 0.5904673933982849 val loss: 0.5750579833984375\n",
      "Batch 8 get train loss: 0.5882015824317932 val loss: 0.5734982490539551\n",
      "Batch 9 get train loss: 0.593615710735321 val loss: 0.5728814601898193\n",
      "Batch 10 get train loss: 0.5833855867385864 val loss: 0.5799612998962402\n",
      "Batch 11 get train loss: 0.5822224617004395 val loss: 0.5719284415245056\n",
      "Batch 12 get train loss: 0.5795847773551941 val loss: 0.5744307637214661\n",
      "Batch 13 get train loss: 0.5744885206222534 val loss: 0.581810712814331\n",
      "Batch 14 get train loss: 0.5708124041557312 val loss: 0.5695597529411316\n",
      "Batch 15 get train loss: 0.5597362518310547 val loss: 0.6082714796066284\n",
      "Batch 16 get train loss: 0.5581087470054626 val loss: 0.5670640468597412\n",
      "Batch 17 get train loss: 0.5322501063346863 val loss: 0.5762184858322144\n",
      "Batch 18 get train loss: 0.516101062297821 val loss: 0.5697875022888184\n",
      "Batch 19 get train loss: 0.4844508469104767 val loss: 0.5682786107063293\n"
     ]
    }
   ],
   "source": [
    "base_model = CNN3D().to(device)\n",
    "load_model_path = 'model_checkpoints/3DCNN_base/model.pt'\n",
    "base_model.load_state_dict(torch.load(load_model_path))\n",
    "base_model_all_params = torch.cat([param.data.view(-1) for param in base_model.parameters()])\n",
    "print('base_model details:')\n",
    "print(f\"All params: mean= {base_model_all_params.mean().item():.6f}, std={base_model_all_params.std().item():.6f}\")\n",
    "\n",
    "peft_model = peft.get_peft_model(base_model, config)\n",
    "print('peft_model details:')\n",
    "all_params = torch.cat([param.data.view(-1) for param in peft_model.parameters()])\n",
    "print(f\"All params: mean= {all_params.mean().item():.6f}, std={all_params.std().item():.6f}\")\n",
    "\n",
    "optimizer_peft = optim.Adam(peft_model.parameters(), lr=0.001)\n",
    "criterion = nn.NLLLoss()\n",
    "train(peft_model, optimizer_peft, criterion, train_dataloader_1, eval_dataloader_1, device, epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f4cc6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save lora adapter\n",
    "adapter_save_path = 'lora_adapter/adapter_1'\n",
    "peft_model.save_pretrained(adapter_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "823c0257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peft_model_from_adapter type <class 'peft.peft_model.PeftModel'>\n",
      "base_model type <class 'MLP_function.CNN3D'>\n",
      "if peft_model and peft_model_from_adapter have same results: True\n",
      "peft_model_from_adapter details:\n",
      "All params: mean= -0.001624, std=0.011556\n"
     ]
    }
   ],
   "source": [
    "# load adapter\n",
    "base_model = CNN3D().to(device)\n",
    "load_model_path = 'model_checkpoints/3DCNN_base/model.pt'\n",
    "base_model.load_state_dict(torch.load(load_model_path))\n",
    "adapter_name = 'lora_adapter/adapter_1'\n",
    "peft_model_from_adapter = peft.PeftModel.from_pretrained(base_model, adapter_name)\n",
    "print('peft_model_from_adapter type',type(peft_model_from_adapter))\n",
    "print('base_model type',type(base_model))\n",
    "with torch.no_grad():\n",
    "    y_peft = peft_model(X_1.to(device))\n",
    "    y_loaded_adapter = peft_model_from_adapter(X_1.to(device))\n",
    "print('if peft_model and peft_model_from_adapter have same results:',torch.allclose(y_peft, y_loaded_adapter))\n",
    "del y_peft, y_loaded_adapter\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "peft_model_from_adapter_all_params = torch.cat([param.data.view(-1) for param in peft_model_from_adapter.parameters()])\n",
    "print('peft_model_from_adapter details:')\n",
    "print(f\"All params: mean= {peft_model_from_adapter_all_params.mean().item():.6f}, std={peft_model_from_adapter_all_params.std().item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7560c0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unmerged_peft_model details: <class 'peft.peft_model.PeftModel'>\n",
      "All params: mean= -0.001624, std=0.011556\n"
     ]
    }
   ],
   "source": [
    "base_model = CNN3D().to(device)\n",
    "load_model_path = 'model_checkpoints/3DCNN_base/model.pt'\n",
    "base_model.load_state_dict(torch.load(load_model_path))\n",
    "\n",
    "adapter_name = 'lora_adapter/adapter_1'\n",
    "unmerged_peft_model = peft.PeftModel.from_pretrained(base_model, adapter_name)\n",
    "print('unmerged_peft_model details:',type(unmerged_peft_model))\n",
    "unmerged_peft_model_all_params = torch.cat([param.data.view(-1) for param in unmerged_peft_model.parameters()])\n",
    "print(f\"All params: mean= {unmerged_peft_model_all_params.mean().item():.6f}, std={unmerged_peft_model_all_params.std().item():.6f}\")\n",
    "merged_model_1 = unmerged_peft_model.merge_and_unload()  \n",
    "\n",
    "model_path = 'model_checkpoints/3DCNN_base'\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "torch.save(original_model.state_dict(), os.path.join(model_path, f\"merged_model_1.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ece542a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 get train loss: 0.5848673582077026 val loss: 0.5117658972740173\n",
      "Batch 1 get train loss: 0.5924632549285889 val loss: 0.5063806176185608\n",
      "Batch 2 get train loss: 0.5938414335250854 val loss: 0.5077865123748779\n",
      "Batch 3 get train loss: 0.5907303094863892 val loss: 0.5112826824188232\n",
      "Batch 4 get train loss: 0.5913812518119812 val loss: 0.5106264352798462\n",
      "Batch 5 get train loss: 0.5782382488250732 val loss: 0.5152074098587036\n",
      "Batch 6 get train loss: 0.5847507119178772 val loss: 0.5055463910102844\n",
      "Batch 7 get train loss: 0.5808209776878357 val loss: 0.5207860469818115\n",
      "Batch 8 get train loss: 0.5787420868873596 val loss: 0.5044960975646973\n",
      "Batch 9 get train loss: 0.568045437335968 val loss: 0.5193659067153931\n",
      "Batch 10 get train loss: 0.5595629215240479 val loss: 0.5115875005722046\n",
      "Batch 11 get train loss: 0.5444388389587402 val loss: 0.5090911388397217\n",
      "Batch 12 get train loss: 0.5368410348892212 val loss: 0.5409210920333862\n",
      "Batch 13 get train loss: 0.5278259515762329 val loss: 0.5180617570877075\n",
      "Batch 14 get train loss: 0.4889063239097595 val loss: 0.4891010522842407\n",
      "Batch 15 get train loss: 0.4605671167373657 val loss: 0.5271088480949402\n",
      "Batch 16 get train loss: 0.42972177267074585 val loss: 0.49678751826286316\n",
      "Batch 17 get train loss: 0.39390242099761963 val loss: 0.4872570037841797\n",
      "Batch 18 get train loss: 0.38689523935317993 val loss: 0.4881781041622162\n",
      "Batch 19 get train loss: 0.33284276723861694 val loss: 0.5130662322044373\n"
     ]
    }
   ],
   "source": [
    "## Fine-tuning with data 2\n",
    "peft_model = peft.get_peft_model(merged_model_1, config)\n",
    "optimizer_peft = optim.Adam(peft_model.parameters(), lr=0.001)\n",
    "criterion = nn.NLLLoss()\n",
    "train(peft_model, optimizer_peft, criterion, train_dataloader_2, eval_dataloader_2, device, epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ce2ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save lora adapter\n",
    "adapter_save_path = 'lora_adapter/adapter_2'\n",
    "peft_model.save_pretrained(adapter_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28b3b31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if the trained model and loaded model are the same: False\n"
     ]
    }
   ],
   "source": [
    "base_model = CNN3D().to(device)\n",
    "load_model_path = 'model_checkpoints/3DCNN_base/merged_model_1.pt'\n",
    "base_model.load_state_dict(torch.load(load_model_path))\n",
    "\n",
    "adapter_name = 'lora_adapter/adapter_2'\n",
    "unmerged_peft_model_2 = peft.PeftModel.from_pretrained(base_model, adapter_name)\n",
    "\n",
    "merged_model_2 = unmerged_peft_model_2.merge_and_unload()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y__loaded = merged_model_2(X_2.to(device))\n",
    "    y_trained = peft_model(X_2.to(device))\n",
    "\n",
    "print('if the trained model and loaded model are the same:', torch.allclose(y__loaded, y_trained))\n",
    "del y__loaded, y_trained\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a8f359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
