{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\envs\\FL\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "from peft import get_peft_model, LoraConfig, TaskType, PeftModel\n",
    "import peft\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from MLP_function import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1])\n",
      "y.sum tensor(284)\n"
     ]
    }
   ],
   "source": [
    "set_all_seeds(45)\n",
    "# 3D CNN\n",
    "X = torch.rand((1000, 1, 28, 28, 28))\n",
    "# set_all_seeds(45)\n",
    "y = (X.sum(dim=[1,2,3,4]) > 11000).long()  # Binary classification based on voxel sum\n",
    "\n",
    "print(y[0 :20])\n",
    "print('y.sum',y.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 800\n",
    "batch_size = 64\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X[:n_train], y[:n_train]),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "eval_dataloader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X[n_train:], y[n_train:]),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "lr = 0.002\n",
    "max_epochs = 30\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All params: mean= 0.000007, std=0.006712\n"
     ]
    }
   ],
   "source": [
    "# Lora\n",
    "# set_all_seeds(45)\n",
    "config = peft.LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"conv.0\", \"conv.3\", 'fc.0'],\n",
    "    # modules_to_save=[\"fc\"] ,\n",
    ")\n",
    "\n",
    "original_model = CNN3D().to(device)\n",
    "original_model_copy = copy.deepcopy(original_model)  # we keep a copy of the original model for later\n",
    "# 计算所有参数拼接后的整体均值和方差\n",
    "all_params = torch.cat([param.data.view(-1) for param in original_model.parameters()])\n",
    "print(f\"All params: mean= {all_params.mean().item():.6f}, std={all_params.std().item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orginal_model type <class 'MLP_function.CNN3D'>\n",
      "All params: mean= 0.000007, std=0.006712\n",
      "before build peft model==========\n",
      "trainalbe parameter in orginal_model:\n",
      "Layer: conv.0.weight | Trainable: True\n",
      "Layer: conv.0.bias | Trainable: True\n",
      "Layer: conv.3.weight | Trainable: True\n",
      "Layer: conv.3.bias | Trainable: True\n",
      "Layer: fc.0.weight | Trainable: True\n",
      "Layer: fc.0.bias | Trainable: True\n",
      "Layer: fc.2.weight | Trainable: True\n",
      "Layer: fc.2.bias | Trainable: True\n",
      "after build peft model==========\n",
      "orginal_model type <class 'MLP_function.CNN3D'>\n",
      "All params: mean= 0.000007, std=0.006712\n",
      "trainalbe parameter in peft_model:\n",
      "Layer: base_model.model.conv.0.base_layer.weight | Trainable: False\n",
      "Layer: base_model.model.conv.0.base_layer.bias | Trainable: False\n",
      "Layer: base_model.model.conv.0.lora_A.default.weight | Trainable: True\n",
      "Layer: base_model.model.conv.0.lora_B.default.weight | Trainable: True\n",
      "Layer: base_model.model.conv.3.base_layer.weight | Trainable: False\n",
      "Layer: base_model.model.conv.3.base_layer.bias | Trainable: False\n",
      "Layer: base_model.model.conv.3.lora_A.default.weight | Trainable: True\n",
      "Layer: base_model.model.conv.3.lora_B.default.weight | Trainable: True\n",
      "Layer: base_model.model.fc.0.base_layer.weight | Trainable: False\n",
      "Layer: base_model.model.fc.0.base_layer.bias | Trainable: False\n",
      "Layer: base_model.model.fc.0.lora_A.default.weight | Trainable: True\n",
      "Layer: base_model.model.fc.0.lora_B.default.weight | Trainable: True\n",
      "Layer: base_model.model.fc.2.weight | Trainable: False\n",
      "Layer: base_model.model.fc.2.bias | Trainable: False\n",
      "trainable params: 92,664 || all params: 1,204,870 || trainable%: 7.6908\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3D CNN\n",
    "## \n",
    "print('orginal_model type',type(original_model))\n",
    "# print('orginal_model_copy type',type(original_model_copy))\n",
    "\n",
    "print('before build peft model==========')\n",
    "print('trainalbe parameter in orginal_model:')\n",
    "for name, param in original_model.named_parameters():\n",
    "    print(f\"Layer: {name} | Trainable: {param.requires_grad}\")\n",
    "\n",
    "# print(\"可训练参数列表:\")\n",
    "# for name, param in original_model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(f\"{name}: {param.shape}\")\n",
    "\n",
    "print('after build peft model==========')\n",
    "print('orginal_model type',type(original_model))\n",
    "peft_model = peft.get_peft_model(original_model_copy, config)\n",
    "optimizer_peft = optim.Adam(peft_model.parameters(), lr=0.001)\n",
    "print('trainalbe parameter in peft_model:')\n",
    "for name, param in peft_model.named_parameters():\n",
    "    print(f\"Layer: {name} | Trainable: {param.requires_grad}\")\n",
    "\n",
    "# print(\"可训练参数列表:\")\n",
    "# for name, param in peft_model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(f\"{name}: {param.shape}\")\n",
    "\n",
    "peft_model.print_trainable_parameters()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 get train loss: 0.6741485595703125 val loss: 0.5019506216049194\n",
      "Batch 1 get train loss: 0.662207841873169 val loss: 0.5949137210845947\n",
      "Batch 2 get train loss: 0.6080417633056641 val loss: 0.5036713480949402\n",
      "Batch 3 get train loss: 0.6113957166671753 val loss: 0.5264621376991272\n",
      "Batch 4 get train loss: 0.6091873645782471 val loss: 0.5454394221305847\n",
      "Batch 5 get train loss: 0.6019322276115417 val loss: 0.5164607167243958\n",
      "Batch 6 get train loss: 0.6136137843132019 val loss: 0.5475145578384399\n",
      "Batch 7 get train loss: 0.6211646199226379 val loss: 0.5145511031150818\n",
      "Batch 8 get train loss: 0.599980354309082 val loss: 0.5161627531051636\n",
      "Batch 9 get train loss: 0.607366144657135 val loss: 0.5365462899208069\n",
      "Batch 10 get train loss: 0.6193227767944336 val loss: 0.5075579881668091\n",
      "Batch 11 get train loss: 0.6150994300842285 val loss: 0.5326802730560303\n",
      "Batch 12 get train loss: 0.6088243722915649 val loss: 0.5208389163017273\n",
      "Batch 13 get train loss: 0.6036936044692993 val loss: 0.5212805867195129\n",
      "Batch 14 get train loss: 0.6028692126274109 val loss: 0.5122635960578918\n",
      "Batch 15 get train loss: 0.6088871955871582 val loss: 0.5690745115280151\n",
      "Batch 16 get train loss: 0.5988736152648926 val loss: 0.5049838423728943\n",
      "Batch 17 get train loss: 0.6044550538063049 val loss: 0.5176917314529419\n",
      "Batch 18 get train loss: 0.5970341563224792 val loss: 0.5040597915649414\n",
      "Batch 19 get train loss: 0.5984479188919067 val loss: 0.517430305480957\n",
      "Batch 20 get train loss: 0.5891991257667542 val loss: 0.5097148418426514\n",
      "Batch 21 get train loss: 0.5839107036590576 val loss: 0.5069316625595093\n",
      "Batch 22 get train loss: 0.5749473571777344 val loss: 0.5672314167022705\n",
      "Batch 23 get train loss: 0.5578547716140747 val loss: 0.5183365941047668\n",
      "Batch 24 get train loss: 0.5306822657585144 val loss: 0.5039252638816833\n",
      "Batch 25 get train loss: 0.5094074606895447 val loss: 0.512996256351471\n",
      "Batch 26 get train loss: 0.4398927092552185 val loss: 0.5863070487976074\n",
      "Batch 27 get train loss: 0.3725658655166626 val loss: 0.5137442350387573\n",
      "Batch 28 get train loss: 0.33297276496887207 val loss: 0.5653449296951294\n",
      "Batch 29 get train loss: 0.2341955155134201 val loss: 0.5330780148506165\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(original_model.parameters(), lr=0.001)\n",
    "criterion = nn.NLLLoss()\n",
    "train(original_model, optimizer, criterion, train_dataloader, eval_dataloader, device,epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(peft_model, optimizer_peft, criterion, train_dataloader, eval_dataloader, device,epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model checkpoints\n",
    "model_path = 'model_checkpoints/3DCNN_base'\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "torch.save(original_model.state_dict(), os.path.join(model_path, f\"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if the trained model and loaded model are the same: True\n"
     ]
    }
   ],
   "source": [
    "load_model_path = 'model_checkpoints/3DCNN_base/model.pt'\n",
    "original_model_copy.load_state_dict(torch.load(load_model_path))\n",
    "with torch.no_grad():\n",
    "    y__loaded = original_model_copy(X.to(device))\n",
    "    y_trained = original_model(X.to(device))\n",
    "    \n",
    "print('if the trained model and loaded model are the same:', torch.allclose(y__loaded, y_trained))\n",
    "del y__loaded, y_trained\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00016380796970808743"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-3*0.99**(900/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save lora adapter\n",
    "adapter_save_path = 'lora_adapter/adapter_1'\n",
    "peft_model.save_pretrained(adapter_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peft_model_from_adapter type <class 'peft.peft_model.PeftModel'>\n",
      "original_model_copy type <class 'MLP_function.CNN3D'>\n",
      "if peft_model and peft_model_from_adapter have same results True\n"
     ]
    }
   ],
   "source": [
    "# load adapter\n",
    "model_name = 'lora_adapter/adapter_1'\n",
    "peft_model_from_adapter = peft.PeftModel.from_pretrained(original_model_copy, model_name)\n",
    "print('peft_model_from_adapter type',type(peft_model_from_adapter))\n",
    "print('original_model_copy type',type(original_model_copy))\n",
    "with torch.no_grad():\n",
    "    y_peft = peft_model(X.to(device))\n",
    "    y_loaded_adapter = peft_model_from_adapter(X.to(device))\n",
    "print('if peft_model and peft_model_from_adapter have same results:',torch.allclose(y_peft, y_loaded_adapter))\n",
    "del y_peft, y_loaded_adapter\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before merging==========\n",
      "unmerged_peft_model type <class 'peft.peft_model.PeftModel'>\n",
      "original_model_copy type <class 'MLP_function.CNN3D'>\n",
      "trainalbe parameter in unmerged_peft_model:\n",
      "Layer: base_model.model.conv.0.base_layer.weight | Trainable: False\n",
      "Layer: base_model.model.conv.0.base_layer.bias | Trainable: False\n",
      "Layer: base_model.model.conv.0.lora_A.default.weight | Trainable: False\n",
      "Layer: base_model.model.conv.0.lora_B.default.weight | Trainable: False\n",
      "Layer: base_model.model.conv.3.base_layer.weight | Trainable: False\n",
      "Layer: base_model.model.conv.3.base_layer.bias | Trainable: False\n",
      "Layer: base_model.model.conv.3.lora_A.default.weight | Trainable: False\n",
      "Layer: base_model.model.conv.3.lora_B.default.weight | Trainable: False\n",
      "Layer: base_model.model.fc.0.base_layer.weight | Trainable: False\n",
      "Layer: base_model.model.fc.0.base_layer.bias | Trainable: False\n",
      "Layer: base_model.model.fc.0.lora_A.default.weight | Trainable: False\n",
      "Layer: base_model.model.fc.0.lora_B.default.weight | Trainable: False\n",
      "Layer: base_model.model.fc.2.weight | Trainable: False\n",
      "Layer: base_model.model.fc.2.bias | Trainable: False\n",
      "after merging==========\n",
      "merged_peft_model type <class 'MLP_function.CNN3D'>\n",
      "unmerged_peft_model type <class 'peft.peft_model.PeftModel'>\n",
      "trainalbe parameter in merged_peft_model:\n",
      "Layer: conv.0.weight | Trainable: False\n",
      "Layer: conv.0.bias | Trainable: False\n",
      "Layer: conv.3.weight | Trainable: False\n",
      "Layer: conv.3.bias | Trainable: False\n",
      "Layer: fc.0.weight | Trainable: False\n",
      "Layer: fc.0.bias | Trainable: False\n",
      "Layer: fc.2.weight | Trainable: False\n",
      "Layer: fc.2.bias | Trainable: False\n"
     ]
    }
   ],
   "source": [
    "### Merging\n",
    "model_name = 'lora_adapter/adapter_1'\n",
    "unmerged_peft_model = peft.PeftModel.from_pretrained(original_model_copy, model_name)\n",
    "print('before merging==========')\n",
    "print('unmerged_peft_model type',type(unmerged_peft_model))\n",
    "print('original_model_copy type',type(original_model_copy))\n",
    "print('trainalbe parameter in unmerged_peft_model:')\n",
    "for name, param in unmerged_peft_model.named_parameters():\n",
    "    print(f\"Layer: {name} | Trainable: {param.requires_grad}\")\n",
    "\n",
    "print('after merging==========')\n",
    "\n",
    "merged_peft_model = unmerged_peft_model.merge_and_unload()  \n",
    "print('merged_peft_model type',type(merged_peft_model))\n",
    "print('unmerged_peft_model type',type(unmerged_peft_model))\n",
    "\n",
    "print('trainalbe parameter in merged_peft_model:')\n",
    "for name, param in merged_peft_model.named_parameters():\n",
    "    print(f\"Layer: {name} | Trainable: {param.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loRA model merged sucessfull: True\n"
     ]
    }
   ],
   "source": [
    "# Compare results of merged model and unmerged model\n",
    "y_unmerged = unmerged_peft_model(X.to(device))\n",
    "y_merged = merged_peft_model(X.to(device))\n",
    "print('loRA model merged sucessfull:',torch.allclose(y_unmerged, y_merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check if merged model same as original model: True\n"
     ]
    }
   ],
   "source": [
    "y_module = module_copy(X.to(device))\n",
    "print('check if merged model same as original model:',torch.allclose(y_module, y_merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module copy: <class 'MLP_function.CNN3D'>\n",
      "Layer: conv.0.weight | Trainable: False\n",
      "Layer: conv.0.bias | Trainable: False\n",
      "Layer: conv.3.weight | Trainable: False\n",
      "Layer: conv.3.bias | Trainable: False\n",
      "Layer: fc.0.weight | Trainable: False\n",
      "Layer: fc.0.bias | Trainable: False\n",
      "Layer: fc.2.weight | Trainable: False\n",
      "Layer: fc.2.bias | Trainable: False\n",
      "\n",
      "module: <class 'MLP_function.CNN3D'>\n",
      "Layer: conv.0.weight | Trainable: True\n",
      "Layer: conv.0.bias | Trainable: True\n",
      "Layer: conv.3.weight | Trainable: True\n",
      "Layer: conv.3.bias | Trainable: True\n",
      "Layer: fc.0.weight | Trainable: True\n",
      "Layer: fc.0.bias | Trainable: True\n",
      "Layer: fc.2.weight | Trainable: True\n",
      "Layer: fc.2.bias | Trainable: True\n"
     ]
    }
   ],
   "source": [
    "print('module copy:',type(module_copy))\n",
    "\n",
    "for name, param in module_copy.named_parameters():\n",
    "    print(f\"Layer: {name} | Trainable: {param.requires_grad}\")\n",
    "\n",
    "print('\\nmodule:',type(module))\n",
    "\n",
    "for name, param in module.named_parameters():\n",
    "    print(f\"Layer: {name} | Trainable: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 集合完全相同： True\n",
      "所有参数值完全相同！\n"
     ]
    }
   ],
   "source": [
    "# 1. 比较 state_dict 的 key 集合\n",
    "orig_sd   = module_copy.state_dict()\n",
    "merged_sd = merged_peft_model.state_dict()\n",
    "\n",
    "orig_keys   = set(orig_sd.keys())\n",
    "merged_keys = set(merged_sd.keys())\n",
    "\n",
    "print(\"Key 集合完全相同：\", orig_keys == merged_keys)\n",
    "if orig_keys != merged_keys:\n",
    "    print(\"仅在原 model 中有的 keys:\", orig_keys - merged_keys)\n",
    "    print(\"仅在 merged_model 中有的 keys:\", merged_keys - orig_keys)\n",
    "\n",
    "#    通常 merge 后参数会变化；如果你只是想确认结构，shape 检查到这里就够了。\n",
    "for k in orig_keys & merged_keys:\n",
    "    a = orig_sd[k]\n",
    "    b = merged_sd[k]\n",
    "    if not torch.equal(a, b):\n",
    "        print(f\"参数值不同: {k} （或使用 torch.allclose 验证近似相等）\")\n",
    "        # 如果想看具体差异，可以打印范数／最大差值\n",
    "        diff = (a - b).abs()\n",
    "        print(f\"   max|Δ| = {diff.max():.3e}, mean|Δ| = {diff.mean():.3e}\")\n",
    "        # 只示例第一个不同的 key，然后跳出\n",
    "        break\n",
    "else:\n",
    "    print(\"所有参数值完全相同！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
